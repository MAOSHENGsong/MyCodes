import logging
import math
import random

import cv2
import numpy as np

from utils.general import colorstr, check_version
from utils.metrics import bbox_ioa
from utils.self_supervised_utils import box_candidates


class Albumentations:
    """
    YOLOv5çš„Albumentationså¢å¼ºç±»ï¼ˆå¯é€‰ï¼Œä»…åœ¨å®‰è£…äº†ç›¸åº”åŒ…æ—¶ä½¿ç”¨ï¼‰

    åŠŸèƒ½:
        åˆå§‹åŒ–å›¾åƒå¢å¼ºæµæ°´çº¿å¹¶åº”ç”¨éšæœºå˜æ¢
        æ”¯æŒè¾¹ç•Œæ¡†å˜æ¢å¹¶ä¿æŒæ ‡æ³¨ä¸€è‡´æ€§

    ä½¿ç”¨æ–¹æ³•:
        transforms = Albumentations()
        image, labels = transforms(image, labels)
    """
    def __init__(self):
        """åˆå§‹åŒ–Albumentationså›¾åƒå¢å¼ºæµæ°´çº¿"""
        self.transform = None
        try:
            import albumentations as A
            check_version(A.__version__, '1.0.3')  # ç‰ˆæœ¬æ£€æŸ¥ï¼Œç¡®ä¿å…¼å®¹æ€§

            # å®šä¹‰å¢å¼ºå˜æ¢ç»„åˆ
            self.transform = A.Compose([
                A.Blur(p=0.01),                  # æ¨¡ç³Šå¤„ç†ï¼Œæ¦‚ç‡1%
                A.MedianBlur(p=0.01),            # ä¸­å€¼æ¨¡ç³Šï¼Œæ¦‚ç‡1%
                A.ToGray(p=0.01),                # è½¬æ¢ä¸ºç°åº¦å›¾ï¼Œæ¦‚ç‡1%
                A.CLAHE(p=0.01),                 # å¯¹æ¯”åº¦å—é™çš„è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–ï¼Œæ¦‚ç‡1%
                A.RandomBrightnessContrast(p=0.0), # éšæœºäº®åº¦å¯¹æ¯”åº¦è°ƒæ•´ï¼Œæ¦‚ç‡0%ï¼ˆä¸å¯ç”¨ï¼‰
                A.RandomGamma(p=0.0),            # éšæœºä¼½é©¬æ ¡æ­£ï¼Œæ¦‚ç‡0%ï¼ˆä¸å¯ç”¨ï¼‰
                A.ImageCompression(quality_lower=75, p=0.0)], # å›¾åƒå‹ç¼©ï¼Œè´¨é‡ä¸‹é™75ï¼Œæ¦‚ç‡0%ï¼ˆä¸å¯ç”¨ï¼‰
                bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'])) # YOLOæ ¼å¼è¾¹ç•Œæ¡†å‚æ•°

            # æ‰“å°å·²å¯ç”¨çš„å¢å¼ºå˜æ¢
            logging.info(colorstr('albumentations: ') + ', '.join(f'{x}' for x in self.transform.transforms if x.p))
        except ImportError:  # æœªå®‰è£…åŒ…ï¼Œè·³è¿‡
            pass
        except Exception as e:
            logging.info(colorstr('albumentations: ') + f'{e}')

    def __call__(self, im, labels, p=1.0):
        """
        åº”ç”¨å¢å¼ºå˜æ¢

        å‚æ•°:
            im: è¾“å…¥å›¾åƒ
            labels: æ ‡ç­¾æ•°ç»„ï¼Œæ ¼å¼ä¸º[class, x_center, y_center, width, height]
            p: åº”ç”¨å˜æ¢çš„æ¦‚ç‡

        è¿”å›:
            im: å˜æ¢åçš„å›¾åƒ
            labels: å˜æ¢åçš„æ ‡ç­¾
        """
        if self.transform and random.random() < p:
            # æ‰§è¡Œå¢å¼ºå˜æ¢
            new = self.transform(image=im, bboxes=labels[:, 1:], class_labels=labels[:, 0])  # åº”ç”¨å˜æ¢
            # æå–å˜æ¢åçš„å›¾åƒå’Œæ ‡ç­¾
            im, labels = new['image'], np.array([[c, *b] for c, b in zip(new['class_labels'], new['bboxes'])])
        return im, labels


def augment_hsv(im, hgain=0.5, sgain=0.5, vgain=0.5):
    """
    HSVé¢œè‰²ç©ºé—´æ•°æ®å¢å¼º

    å‚æ•°:
        im: è¾“å…¥å›¾åƒ(BGRæ ¼å¼ numpyæ•°ç»„)
        hgain: è‰²è°ƒå¢ç›Šç³»æ•°(0è¡¨ç¤ºä¸å¢å¼º)
        sgain: é¥±å’Œåº¦å¢ç›Šç³»æ•°(0è¡¨ç¤ºä¸å¢å¼º)
        vgain: æ˜åº¦å¢ç›Šç³»æ•°(0è¡¨ç¤ºä¸å¢å¼º)

    å¤„ç†é€»è¾‘:
        1. ç”Ÿæˆéšæœºå¢ç›Šç³»æ•°ï¼ŒèŒƒå›´ä¸º[1-gain, 1+gain]
        2. å°†å›¾åƒä»BGRé¢œè‰²ç©ºé—´è½¬æ¢ä¸ºHSV
        3. åˆ†åˆ«å¯¹è‰²è°ƒã€é¥±å’Œåº¦ã€æ˜åº¦é€šé“åº”ç”¨æŸ¥æ‰¾è¡¨å˜æ¢:
           - è‰²è°ƒ: å¾ªç¯å–æ¨¡(0-180èŒƒå›´)
           - é¥±å’Œåº¦/æ˜åº¦: è£å‰ªåˆ°0-255èŒƒå›´
        4. è½¬æ¢å›BGRé¢œè‰²ç©ºé—´å¹¶ç›´æ¥ä¿®æ”¹è¾“å…¥å›¾åƒ
    """
    if hgain or sgain or vgain:
        r = np.random.uniform(-1, 1, 3) * [hgain, sgain, vgain] + 1  # ç”Ÿæˆéšæœºå¢ç›Šç³»æ•°ï¼ˆèŒƒå›´[1-gain, 1+gain]ï¼‰
        hue, sat, val = cv2.split(cv2.cvtColor(im, cv2.COLOR_BGR2HSV))  # è½¬æ¢è‡³HSVé¢œè‰²ç©ºé—´å¹¶æ‹†åˆ†é€šé“
        dtype = im.dtype  # ä¿å­˜åŸå§‹æ•°æ®ç±»å‹ï¼ˆç”¨äºåç»­è½¬æ¢ï¼‰

        x = np.arange(0, 256, dtype=r.dtype)  # ç”Ÿæˆ0-255çš„ç´¢å¼•æ•°ç»„
        lut_hue = ((x * r[0]) % 180).astype(dtype)  # è‰²è°ƒé€šé“å¾ªç¯å–æ¨¡ï¼ˆHSVè‰²è°ƒèŒƒå›´0-180ï¼‰
        lut_sat = np.clip(x * r[1], 0, 255).astype(dtype)  # é¥±å’Œåº¦é€šé“è£å‰ªåˆ°0-255èŒƒå›´
        lut_val = np.clip(x * r[2], 0, 255).astype(dtype)  # æ˜åº¦é€šé“è£å‰ªåˆ°0-255èŒƒå›´

        im_hsv = cv2.merge((cv2.LUT(hue, lut_hue), cv2.LUT(sat, lut_sat), cv2.LUT(val, lut_val)))  # åº”ç”¨æŸ¥æ‰¾è¡¨å˜æ¢
        cv2.cvtColor(im_hsv, cv2.COLOR_HSV2BGR, dst=im)  # è½¬æ¢å›BGRé¢œè‰²ç©ºé—´å¹¶ç›´æ¥ä¿®æ”¹åŸå›¾åƒ


def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):
    """
    å›¾åƒç¼©æ”¾ä¸å¡«å……ï¼ˆLetterboxå˜æ¢ï¼‰ï¼Œæ»¡è¶³æ­¥é•¿å€æ•°çº¦æŸ

    å‚æ•°:
        im: è¾“å…¥å›¾åƒ(numpyæ•°ç»„ï¼Œshapeä¸º[H, W, C])
        new_shape: ç›®æ ‡å°ºå¯¸ï¼Œå¯ä¸ºæ•´æ•°æˆ–å…ƒç»„(int, int)
        color: å¡«å……è¾¹æ¡†é¢œè‰²(RGBæ ¼å¼)
        auto: æ˜¯å¦è‡ªåŠ¨è®¡ç®—æœ€å°å¡«å……ï¼ˆä½¿å¡«å……åå°ºå¯¸ä¸ºstrideå€æ•°ï¼‰
        scaleFill: æ˜¯å¦æ‹‰ä¼¸å›¾åƒè‡³å®Œå…¨è¦†ç›–ç›®æ ‡å°ºå¯¸ï¼ˆå¯èƒ½å˜å½¢ï¼‰
        scaleup: æ˜¯å¦å…è®¸æ”¾å¤§å›¾åƒï¼ˆä¸ºFalseæ—¶ä»…ç¼©å°ï¼‰
        stride: æ­¥é•¿çº¦æŸï¼ˆç”¨äºautoæ¨¡å¼ä¸‹çš„å°ºå¯¸å¯¹é½ï¼‰

    è¿”å›:
        im: å¤„ç†åçš„å›¾åƒ
        ratio: ç¼©æ”¾æ¯”ä¾‹ï¼ˆå®½, é«˜ï¼‰
        pad: è¾¹æ¡†å¡«å……é‡ï¼ˆå®½æ–¹å‘, é«˜æ–¹å‘ï¼‰

    å¤„ç†é€»è¾‘:
        1. è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼Œä¼˜å…ˆä¿æŒåŸå§‹å®½é«˜æ¯”
        2. æ ¹æ®scaleupå‚æ•°é™åˆ¶ç¼©æ”¾æ¯”ä¾‹ï¼ˆä¸æ”¾å¤§æˆ–è‡ªç”±ç¼©æ”¾ï¼‰
        3. è®¡ç®—åŸå§‹ç¼©æ”¾åçš„å°ºå¯¸(new_unpad)å’Œè¾¹æ¡†å¡«å……é‡(dw, dh)
        4. autoæ¨¡å¼ä¸‹å°†å¡«å……é‡å¯¹é½åˆ°strideå€æ•°
        5. scaleFillæ¨¡å¼ä¸‹ç¦ç”¨è¾¹æ¡†å¡«å……ï¼Œç›´æ¥æ‹‰ä¼¸å›¾åƒ
        6. æ‰§è¡Œå›¾åƒç¼©æ”¾å’Œè¾¹æ¡†å¡«å……
    """
    shape = im.shape[:2]  # å½“å‰å›¾åƒå°ºå¯¸[é«˜, å®½]
    if isinstance(new_shape, int):
        new_shape = (new_shape, new_shape)

    # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼ˆå–å®½é«˜æ¯”æœ€å°å€¼ï¼Œä¿æŒåŸå§‹æ¯”ä¾‹ï¼‰
    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])
    if not scaleup:  # ç¦æ­¢æ”¾å¤§å›¾åƒï¼ˆä»…ç¼©å°æˆ–ä¿æŒåŸå°ºå¯¸ï¼‰
        r = min(r, 1.0)

    ratio = r, r  # å®½é«˜ç¼©æ”¾æ¯”ä¾‹ï¼ˆç­‰æ¯”ä¾‹ç¼©æ”¾ï¼‰
    new_unpad = (int(round(shape[1] * r)), int(round(shape[0] * r)))  # åŸå§‹ç¼©æ”¾åçš„å°ºå¯¸ï¼ˆæœªå¡«å……ï¼‰
    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # å®½é«˜æ–¹å‘éœ€å¡«å……çš„æ€»åƒç´ æ•°

    if auto:  # è‡ªåŠ¨æ¨¡å¼ï¼šä½¿å¡«å……åçš„å°ºå¯¸ä¸ºstrideæ•´æ•°å€
        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # å–æ¨¡è¿ç®—å®ç°æœ€å°éè´Ÿå¡«å……
    elif scaleFill:  # æ‹‰ä¼¸æ¨¡å¼ï¼šç›´æ¥å¡«æ»¡ç›®æ ‡å°ºå¯¸ï¼ˆå¯èƒ½å˜å½¢ï¼‰
        dw, dh = 0.0, 0.0
        new_unpad = (new_shape[1], new_shape[0])
        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # éç­‰æ¯”ä¾‹ç¼©æ”¾æ¯”ä¾‹

    dw /= 2  # å·¦å³è¾¹æ¡†å¡«å……é‡ï¼ˆæ€»å¡«å……é‡å‡åˆ†ä¸¤ä¾§ï¼‰
    dh /= 2  # ä¸Šä¸‹è¾¹æ¡†å¡«å……é‡ï¼ˆæ€»å¡«å……é‡å‡åˆ†ä¸¤ä¾§ï¼‰

    if shape[::-1] != new_unpad:  # éœ€è¦æ‰§è¡Œç¼©æ”¾ï¼ˆå½“åŸå§‹å°ºå¯¸ä¸ç¼©æ”¾åå°ºå¯¸ä¸ä¸€è‡´æ—¶ï¼‰
        # ä½¿ç”¨åŒçº¿æ€§æ’å€¼è°ƒæ•´å›¾åƒå¤§å°ï¼ˆä¿æŒå¹³æ»‘ï¼‰
        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)
        # im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_NEAREST)  # å¯åˆ‡æ¢ä¸ºæœ€è¿‘é‚»æ’å€¼

    # è®¡ç®—å®é™…å¡«å……åƒç´ æ•°ï¼ˆå››èˆäº”å…¥å¤„ç†æµ®ç‚¹è¯¯å·®ï¼‰
    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))

    # æ·»åŠ è¾¹æ¡†ï¼ˆBORDER_CONSTANTè¡¨ç¤ºçº¯è‰²å¡«å……ï¼‰
    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)
    return im, ratio, (dw, dh)


def random_perspective_keypoints(img, targets=(), segments=(), degrees=10, translate=.1, scale=.1, shear=10,
                                 perspective=0.0, num_points=0, border=(0, 0)):
    """
    ğŸ”¥ å¸¦å…³é”®ç‚¹å¤„ç†çš„éšæœºå‡ ä½•å˜æ¢å¢å¼º

    å‚æ•°:
        img: è¾“å…¥å›¾åƒ(HWCæ ¼å¼)
        targets: ç›®æ ‡æ•°æ®[ç±»åˆ«,x1,y1,x2,y2,å…³é”®ç‚¹åæ ‡...]
        segments: å¯é€‰åˆ†å‰²å¤šè¾¹å½¢
        degrees: éšæœºæ—‹è½¬è§’åº¦èŒƒå›´
        translate: å¹³ç§»æ¯”ä¾‹èŒƒå›´
        perspective: é€è§†å˜æ¢å¼ºåº¦(0-1)
        num_points: å…³é”®ç‚¹æ•°é‡(0è¡¨ç¤ºæ— )
        border: å›¾åƒè¾¹ç•Œçš„å¡«å……åƒç´ 

    æ ¸å¿ƒå¤„ç†:
        1. æ„é€ ç»„åˆå˜æ¢çŸ©é˜µ(M = TÂ·SÂ·RÂ·PÂ·C)
        2. åº”ç”¨ä»¿å°„/é€è§†å˜æ¢åˆ°å›¾åƒ
        3. åŠ¨æ€è®¡ç®—ç›®æ ‡æ¡†ä¸å…³é”®ç‚¹æ–°åæ ‡
        4. å…³é”®ç‚¹æœ‰æ•ˆæ€§æ ¡éªŒä¸æ•°æ®ä¿®å¤

    å…³é”®ç»†èŠ‚:
        ğŸ“Œ çŸ©é˜µå˜æ¢é¡ºåº: å¹³ç§»->å‰ªåˆ‡->æ—‹è½¬->é€è§†->ä¸­å¿ƒåŒ–
        ğŸ“Œ åˆ†å‰²/æ¡†ä¸¤ç§å¤„ç†æ¨¡å¼ï¼š
           - ä½¿ç”¨4ç‚¹æ—¶ä¸ºåˆ†å‰²æ¨¡å¼(æ¯ä¸ªæ¡†4è§’ç‚¹)
           - ä½¿ç”¨num_pointsæ—¶å¤„ç†å…³é”®ç‚¹åæ ‡
        ğŸ“Œ å…³é”®ç‚¹ç¢°è¾¹æ£€æµ‹(check_board=Trueæ—¶æ¿€æ´»)ï¼š
           - å‡ºç•Œåæ ‡æ ‡è®°ä¸º-1
           - å…¨æ— æ•ˆå…³é”®ç‚¹æ¢å¤åŸå§‹æ•°æ®
        ğŸ“Œ ä½¿ç”¨0.1é˜ˆå€¼è¿‡æ»¤æ— æ•ˆboxï¼š
           - ä¿ç•™é¢ç§¯å˜åŒ–åˆç†çš„ç›®æ ‡
           - é˜²æ­¢è¿‡å°çš„é”™è¯¯æ£€æµ‹æ¡†

    æ•°æ®æ ¼å¼:
        targetsç»“æ„:
        [class, x_min, y_min, x_max, y_max, x1,y1,...xn,yn]
        å…³é”®ç‚¹é¡ºåºéœ€ä¸åŸå§‹æ ‡æ³¨ä¸¥æ ¼å¯¹åº”
    """
    # torchvision.transforms.RandomAffine(degrees=(-10, 10), translate=(.1, .1), scale=(.9, 1.1), shear=(-10, 10))
    # targets = [cls, xyxy, x0, y0, x1, y2, x2, y2, x3, y3]

    height = img.shape[0] + border[0] * 2  # shape(h,w,c)
    width = img.shape[1] + border[1] * 2

    # Center
    C = np.eye(3)
    C[0, 2] = -img.shape[1] / 2  # x translation (pixels)
    C[1, 2] = -img.shape[0] / 2  # y translation (pixels)

    # Perspective
    P = np.eye(3)
    P[2, 0] = random.uniform(-perspective, perspective)  # x perspective (about y)
    P[2, 1] = random.uniform(-perspective, perspective)  # y perspective (about x)

    # Rotation and Scale
    R = np.eye(3)
    a = random.uniform(-degrees, degrees)
    # a += random.choice([-180, -90, 0, 90])  # add 90deg rotations to small rotations
    s = random.uniform(1 - scale, 1 + scale)
    # s = 2 ** random.uniform(-scale, scale)
    R[:2] = cv2.getRotationMatrix2D(angle=a, center=(0, 0), scale=s)

    # Shear
    S = np.eye(3)
    S[0, 1] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # x shear (deg)
    S[1, 0] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # y shear (deg)

    # Translation
    T = np.eye(3)
    T[0, 2] = random.uniform(0.5 - translate, 0.5 + translate) * width  # x translation (pixels)
    T[1, 2] = random.uniform(0.5 - translate, 0.5 + translate) * height  # y translation (pixels)

    # Combined rotation matrix
    M = T @ S @ R @ P @ C  # order of operations (right to left) is IMPORTANT
    if (border[0] != 0) or (border[1] != 0) or (M != np.eye(3)).any():  # image changed
        if perspective:
            img = cv2.warpPerspective(img, M, dsize=(width, height), borderValue=(114, 114, 114))
        else:  # affine
            img = cv2.warpAffine(img, M[:2], dsize=(width, height), borderValue=(114, 114, 114))

    # Visualize
    # import matplotlib.pyplot as plt
    # ax = plt.subplots(1, 2, figsize=(12, 6))[1].ravel()
    # ax[0].imshow(img[:, :, ::-1])  # base
    # ax[1].imshow(img2[:, :, ::-1])  # warped
    check_board = False
    # Transform label coordinates
    n = len(targets)
    if n:
        use_segments = any(x.any() for x in segments)
        new = np.zeros((n, 4))
        if num_points == 0:  # warp segments
            xy = np.ones((n * 4, 3))
            xy[:, :2] = targets[:, [1, 2, 3, 4, 1, 4, 3, 2]].reshape(n * 4, 2)  # x1y1, x2y2, x1y2, x2y1
            xy = xy @ M.T  # transform
            xy = (xy[:, :2] / xy[:, 2:3] if perspective else xy[:, :2]).reshape(n, 8)  # perspective rescale or affine

            # create new boxes
            x = xy[:, [0, 2, 4, 6]]
            y = xy[:, [1, 3, 5, 7]]
            new = np.concatenate((x.min(1), y.min(1), x.max(1), y.max(1))).reshape(4, n).T

            # clip
            new[:, [0, 2]] = new[:, [0, 2]].clip(0, width)
            new[:, [1, 3]] = new[:, [1, 3]].clip(0, height)

        else:  # warp boxes
            xy = np.ones((n * (4 + num_points), 3))
            # xy = np.ones((n * 8, 3))
            index = [1, 2, 3, 4, 1, 4, 3, 2]
            index_landmark = list(range(5, 5 + num_points * 2))
            index.extend(index_landmark)
            xy[:, :2] = targets[:, index].reshape(n * (4 + num_points), 2)
            # xy[:, :2] = targets[:, [1, 2, 3, 4, 1, 4, 3, 2, 5, 6, 7, 8, 9, 10, 11, 12]].reshape(n * 8, 2)  # x1y1, x2y2, x1y2, x2y1
            xy = xy @ M.T  # transform
            if perspective:
                xy = (xy[:, :2] / xy[:, 2:3]).reshape(n, 2 * (4 + num_points))  # rescale
            else:  # affine
                # xy = xy[:, :2].reshape(n, 2*8)
                xy = xy[:, :2].reshape(n, 2 * (4 + num_points))
            # create new boxes
            x = xy[:, [0, 2, 4, 6]]
            y = xy[:, [1, 3, 5, 7]]
            landmarks_index = list(range(8, 8 + num_points * 2))
            # landmarks = xy[:, [8, 9, 10, 11, 12, 13, 14, 15]]
            landmarks = xy[:, landmarks_index]
            # mask = np.array(targets[:, 5:] > 0, dtype=np.int32)

            # æ£€æŸ¥è¿›è¡Œæ•°æ®å¢å¼ºåçš„å…³é”®ç‚¹æ ‡æ³¨æ˜¯å¦æœ‰ç¢°è¾¹è¡Œä¸ºï¼Œå¦‚æœæœ‰ï¼Œè¯¥æ ‡æ³¨æ— æ•ˆ
            if check_board:
                mask = np.array(landmarks > 0, dtype=np.int32)
                landmarks = landmarks * mask
                landmarks = landmarks + mask - 1
                # landmarks[lmk_non_valid_index] = targets[lmk_non_valid_index, 5:]

                # landmarks = np.where(landmarks < 0, -1, landmarks)
                landmarks[:, [0, 2, 4, 6]] = np.where(landmarks[:, [0, 2, 4, 6]] > width, -1,
                                                      landmarks[:, [0, 2, 4, 6]])
                landmarks[:, [1, 3, 5, 7]] = np.where(landmarks[:, [1, 3, 5, 7]] > height, -1,
                                                      landmarks[:, [1, 3, 5, 7]])
                # landmarks_tmp = landmarks.copy()
                for ind, landmark in enumerate(landmarks):
                    if -1 in landmark:
                        landmarks[ind] = np.ones((1, num_points * 2)) * -1

            # landmarks[:, 0] = np.where(landmarks[:, 1] == -1, -1, landmarks[:, 0])
            # landmarks[:, 1] = np.where(landmarks[:, 0] == -1, -1, landmarks[:, 1])

            # landmarks[:, 2] = np.where(landmarks[:, 3] == -1, -1, landmarks[:, 2])
            # landmarks[:, 3] = np.where(landmarks[:, 2] == -1, -1, landmarks[:, 3])

            # landmarks[:, 4] = np.where(landmarks[:, 5] == -1, -1, landmarks[:, 4])
            # landmarks[:, 5] = np.where(landmarks[:, 4] == -1, -1, landmarks[:, 5])

            # landmarks[:, 6] = np.where(landmarks[:, 7] == -1, -1, landmarks[:, 6])
            # landmarks[:, 7] = np.where(landmarks[:, 6] == -1, -1, landmarks[:, 7])
            ori_targets = targets.copy()

            # æ£€æŸ¥8ä¸ªå…³é”®ç‚¹æ˜¯å¦éƒ½ä¸º-1, è¡¨è¿°åœ¨è¿›è¡Œæ•°æ®å¢å¼ºä¹‹å‰çš„æ ‡æ³¨å°±å·²ç»æ— æ•ˆ
            targets[:, 5:] = landmarks
            non_valid_index = ((ori_targets[:, 5:] == -1).sum(1) == num_points * 2)  # [false true false] example
            targets[non_valid_index, 5:] = ori_targets[non_valid_index, 5:]

            new = np.concatenate((x.min(1), y.min(1), x.max(1), y.max(1))).reshape(4, n).T

            # clip
            new[:, [0, 2]] = new[:, [0, 2]].clip(0, width)
            new[:, [1, 3]] = new[:, [1, 3]].clip(0, height)

        # filter candidates
        i = box_candidates(box1=targets[:, 1:5].T * s, box2=new.T, area_thr=0.01 if use_segments else 0.10)
        targets = targets[i]
        # print('before:', targets)
        targets[:, 1:5] = new[i]
        # print('after:', targets)

    return img, targets

def copy_paste(im, labels, segments, p=0.5):
    """ğŸ­ Copy-Pasteæ•°æ®å¢å¼º(æ°´å¹³ç¿»è½¬ç‰ˆ)ï¼Œæå‡å°ç›®æ ‡æ£€æµ‹èƒ½åŠ›

    å‚æ•°:
        im: åŸå§‹å›¾åƒ(numpyæ•°ç»„)
        labels: ç›®æ ‡æ ‡ç­¾æ•°ç»„[class,x1,y1,x2,y2]
        segments: åˆ†å‰²å¤šè¾¹å½¢åæ ‡åˆ—è¡¨
        p: æ‰§è¡Œæ¦‚ç‡(é»˜è®¤0.5)

    æ ¸å¿ƒé€»è¾‘:
        1. æŒ‰æ¦‚ç‡éšæœºé€‰å–éƒ¨åˆ†å®ä¾‹
        2. ç”Ÿæˆæ°´å¹³é•œåƒå‰¯æœ¬
        3. è®¡ç®—IOAé¿å…ç›®æ ‡è¿‡åº¦é‡å 
        4. é€šè¿‡ä½è¿ç®—åˆæˆæ–°å›¾åƒ

    å…³é”®ç»†èŠ‚:
        ğŸ”„ é•œåƒç¿»è½¬å¤„ç†ï¼š
           - è®¡ç®—æ°´å¹³ç¿»è½¬åçš„xåæ ‡ï¼šw - x
           - åŒæ­¥è°ƒæ•´è¾¹ç•Œæ¡†åæ ‡é¡ºåº
        ğŸ¯ é®æŒ¡æ§åˆ¶ï¼š
           - 30%çš„IOAé˜ˆå€¼è¿‡æ»¤é‡å ç›®æ ‡
           - ä¿æŒåŸå§‹æ ‡ç­¾æ•°æ®å®Œæ•´æ€§
        ğŸ–Œï¸ å›¾åƒåˆæˆï¼š
           - ä½¿ç”¨cv2è½®å»“ç»˜åˆ¶ç”Ÿæˆæ©è†œ
           - ä½æ“ä½œå®ç°åƒç´ çº§èåˆ

    æ³¨æ„:
        - åŸå›¾ä¼šè¢«ç›´æ¥ä¿®æ”¹(in-placeæ“ä½œ)
        - segmentsä¼šè¿½åŠ æ–°çš„å¤šè¾¹å½¢åæ ‡
        - è¦æ±‚è¾“å…¥labelsä¸ºnumpyæ•°ç»„æ ¼å¼
    """
    n = len(segments)
    if p and n:
        h, w, c = im.shape  # height, width, channels
        im_new = np.zeros(im.shape, np.uint8)
        for j in random.sample(range(n), k=round(p * n)):
            l, s = labels[j], segments[j]
            box = w - l[3], l[2], w - l[1], l[4]
            ioa = bbox_ioa(box, labels[:, 1:5])  # intersection over area
            if (ioa < 0.30).all():  # allow 30% obscuration of existing labels
                labels = np.concatenate((labels, [[l[0], *box]]), 0)
                segments.append(np.concatenate((w - s[:, 0:1], s[:, 1:2]), 1))
                cv2.drawContours(im_new, [segments[j].astype(np.int32)], -1, (255, 255, 255), cv2.FILLED)

        result = cv2.bitwise_and(src1=im, src2=im_new)
        result = cv2.flip(result, 1)  # augment segments (flip left-right)
        i = result > 0  # pixels to replace
        # i[:, :] = result.max(2).reshape(h, w, 1)  # act over ch
        im[i] = result[i]  # cv2.imwrite('debug.jpg', im)  # debug

    return im, labels, segments


def mixup(im, labels, im2, labels2):
    """ğŸ¨ MixUpæ•°æ®å¢å¼ºï¼Œèåˆä¸¤å¼ å›¾åƒåŠæ ‡ç­¾

    å‚æ•°:
        im/labels: ä¸»å›¾åƒåŠæ ‡ç­¾
        im2/labels2: æ··åˆå›¾åƒåŠæ ‡ç­¾
    æ ¸å¿ƒ:
        - ä½¿ç”¨Î²åˆ†å¸ƒ(Î±=Î²=32)ç”Ÿæˆæ··åˆæ¯”r
        - çº¿æ€§å åŠ å›¾åƒ: im*r + im2*(1-r)
        - åˆå¹¶æ ‡ç­¾æ•°æ®
    ç‰¹ç‚¹:
        - å¢å¼ºæ¨¡å‹é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›
        - ä¿ç•™ä¸¤å¼ å›¾åƒçš„å…¨éƒ¨æ ‡æ³¨ä¿¡æ¯
        - æ··åˆæ¯”ä¾‹åå‘ä¸­é—´å€¼(Î²åˆ†å¸ƒç‰¹æ€§)
    """
    r = np.random.beta(32.0, 32.0)
    im = (im * r + im2 * (1 - r)).astype(np.uint8)
    labels = np.concatenate((labels, labels2), 0)
    return im, labels

